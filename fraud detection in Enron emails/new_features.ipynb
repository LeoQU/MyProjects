{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'Decision Tree': {   'F1 Score': 0.43915343915343907,\n",
      "                         'precision': 0.52380952380952384,\n",
      "                         'recall': 0.38888888888888884},\n",
      "    'Gaussion Naive Bayes': {   'F1 Score': 0.25108225108225107,\n",
      "                                'precision': 0.43888888888888888,\n",
      "                                'recall': 0.33333333333333331},\n",
      "    'SVM': {   'F1 Score': 0.0, 'precision': 0.0, 'recall': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "from time import time\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "# fix Sanjay Bhatnagar's data\n",
    "data_dict['BHATNAGAR SANJAY']['director_fees'] = 0\n",
    "data_dict['BHATNAGAR SANJAY']['exercised_stock_options'] = 15456290\n",
    "data_dict['BHATNAGAR SANJAY']['expenses'] = 137864\n",
    "data_dict['BHATNAGAR SANJAY']['other'] = 0\n",
    "data_dict['BHATNAGAR SANJAY']['restricted_stock'] = 2604490\n",
    "data_dict['BHATNAGAR SANJAY']['restricted_stock_deferred'] = -2604490\n",
    "data_dict['BHATNAGAR SANJAY']['total_payments'] = 137864\n",
    "data_dict['BHATNAGAR SANJAY']['total_stock_value'] = 15456290\n",
    "\n",
    "# fix Robert Belfer's data\n",
    "data_dict['BELFER ROBERT']['deferral_payments'] = 0\n",
    "data_dict['BELFER ROBERT']['deferred_income'] = -102500\n",
    "data_dict['BELFER ROBERT']['director_fees'] = 102500\n",
    "data_dict['BELFER ROBERT']['exercised_stock_options'] = 0\n",
    "data_dict['BELFER ROBERT']['expenses'] = 3285\n",
    "data_dict['BELFER ROBERT']['restricted_stock'] = 44093\n",
    "data_dict['BELFER ROBERT']['restricted_stock_deferred'] = -44093\n",
    "data_dict['BELFER ROBERT']['total_payments'] = 3285\n",
    "data_dict['BELFER ROBERT']['total_stock_value'] = 0\n",
    "\n",
    "### Task 1: Identify outliers\n",
    "# The details of identifying outliers are presented in identify_outliers.html\n",
    "non_employee = ['TOTAL', 'THE TRAVEL AGENCY IN THE PARK']\n",
    "outliers_1 = ['FREVERT MARK A', 'ALLEN PHILLIP K']\n",
    "outliers_2 = ['BECK SALLY W', 'KITCHEN LOUISE', 'PAI LOU L', 'SHAPIRO RICHARD S', 'URQUHART JOHN A']\n",
    "\n",
    "for i in non_employee + outliers_1:\n",
    "    data_dict.pop(i) # remove 4 outliers\n",
    "\n",
    "### Task 2: Design new features\n",
    "# list all the numeric features\n",
    "all_features = ['poi', 'bonus', 'deferral_payments', 'deferred_income', 'director_fees', 'exercised_stock_options', 'expenses', 'from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi', 'loan_advances', 'long_term_incentive', 'other', 'restricted_stock', 'restricted_stock_deferred', 'salary', 'shared_receipt_with_poi', 'to_messages', 'total_payments', 'total_stock_value']\n",
    "\n",
    "# introduce two new features\n",
    "new_features = ['NaN_num', 'poi_message_over_total_message']\n",
    "\n",
    "# return the number of 'NaN' in a dictionary\n",
    "def count_NaN(dic):\n",
    "    count = 0\n",
    "    for value in dic.values():\n",
    "        if value == 'NaN':\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# insert new features into dataset\n",
    "if new_features != []:\n",
    "    for value in data_dict.values():\n",
    "        value[new_features[0]] = count_NaN(value)\n",
    "        if value['from_poi_to_this_person'] != 'NaN' and value['from_this_person_to_poi'] != 'NaN' and value['from_messages'] != 'NaN' and value['to_messages'] != 'NaN':\n",
    "            value[new_features[1]] = ( float(value['from_poi_to_this_person']) + float(value['from_this_person_to_poi']) ) / ( float(value['from_messages']) + float(value['to_messages']) )\n",
    "        else: value[new_features[1]] = 'NaN'\n",
    "\n",
    "features_list = ['poi', 'bonus', 'deferred_income', 'expenses', 'total_payments', 'total_stock_value']\n",
    "features_list = ['poi', 'bonus', 'deferred_income', 'expenses', 'total_payments', 'total_stock_value'] + [new_features[0]]\n",
    "features_list = ['poi', 'bonus', 'deferred_income', 'expenses', 'total_payments', 'total_stock_value'] + [new_features[1]]\n",
    "\n",
    "### Task 4&5: Try a varity of classifiers and Tune classifier parameters\n",
    "# Extract features and labels from the dataset\n",
    "my_dataset = data_dict\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# Feature scaling\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "features_scaled = min_max_scaler.fit_transform(features)\n",
    "\n",
    "# split train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# try different classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "classifiers = [GaussianNB, svm.SVC,tree.DecisionTreeClassifier]\n",
    "clf_names = ['Gaussion Naive Bayes', 'SVM', 'Decision Tree']\n",
    "results = {}\n",
    "for name, clf_cls in zip(clf_names, classifiers):\n",
    "    tmp_dict = {}\n",
    "    # use KFold for cross validation\n",
    "    tmp_dict['precision'] = cross_val_score( clf_cls(), features, labels, cv=StratifiedKFold(n_splits=3, shuffle=True), scoring='precision').mean()\n",
    "    tmp_dict['recall'] = cross_val_score( clf_cls(), features, labels, cv=StratifiedKFold(n_splits=3, shuffle=True), scoring='recall').mean()\n",
    "    tmp_dict['F1 Score'] = cross_val_score( clf_cls(), features, labels, cv=StratifiedKFold(n_splits=3, shuffle=True), scoring='f1').mean()\n",
    "    results[name] = tmp_dict\n",
    "\n",
    "# validation and metrics\n",
    "pp.pprint(results)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
