{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenStreetMap Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map Area:\n",
    "Sydney, NSW, Australia\n",
    "\n",
    "https://www.openstreetmap.org/relation/5750005\n",
    "\n",
    "https://mapzen.com/data/metro-extracts/metro/sydney_australia/\n",
    "\n",
    "The map is the city where I am living. I will explore the map data to find interesting things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Overview:\n",
    "\n",
    "Sydney_Australia.osm ......... 303.9 MB\n",
    "\n",
    "Sydney_Australia.db .......... 162.1 MB\n",
    "\n",
    "nodes.csv ............. 112.3 MB\n",
    "\n",
    "nodes_tags.csv ........ 5.3 MB\n",
    "\n",
    "ways.csv .............. 11 MB\n",
    "\n",
    "ways_tags.csv ......... 38.7 MB\n",
    "\n",
    "ways_nodes.cv ......... 21.2 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling:\n",
    "    \n",
    "In this project, I apply SQL database (sqlite) to store the map data. Before importing all data into the database, I process data wrangling to fix errors in the dataset:\n",
    "\n",
    "1. I apply regular expressions to check consistency of the data in the nodes.csv and ways.csv files. The nodes.csv and ways.csv files store the basic information of nodes and ways in the map, e.g., users who mark the nodes and ways, coordinates and identities of nodes and ways.\n",
    "2. I check the nodes_tags and ways_tags files, which store the descriptions of nodes and ways. I find some errors in the file and fix these errors when generating all these csv files.\n",
    "3. I explore the ways_nodes.csv file, which describes the relations between nodes and ways. As all the data in ways_nodes.csv are generated from nodes.csv and ways.csv files, it is not necessary to clean ways_nodes data separately.\n",
    "\n",
    "Problems in OSM DATA:\n",
    "\n",
    "I find some problems in the dataset as follows:\n",
    "\n",
    "1. In nodes_tags.csv and ways_tags.csv, I find two a string key named \"city_1\" with values \"Sydney\" and \"Roseberry\". As I notice that all the other keys describing city are named 'city', I think 'city_1' should be a manual input error. As these are only two errors in this case, I fix the errors manually.\n",
    "\n",
    "2. I find that some of the suburb names under tag k = 'addr:city' are not the names of Sydney suburbs. That may because some of these suburb may be famous places rather than a offical suburb, e.g., Darling Harbour, or they belong to other regions near Sydney, e.g., central coast. Thus, I keep these suburb names. On the other name, some names of Sydney suburbs are not formatted correctly. For example, wentworth Point, the first 'w' is not capitcal. Thus, I write a piece of codes to make sure all the names starting with capital letters. The codes are shown in the following paragraph.\n",
    "\n",
    "3. A valid Sydney postcode is a 4-digit number starting with '2'. I check all the postcodes and find some invalid postcodes as follows:  \n",
    "['NSW 2010',\n",
    " 'NSW 2000',\n",
    " '210',\n",
    " 'NSW 2010',\n",
    " 'NSW 2010',\n",
    " 'NSW 2567',\n",
    " 'NSW 2068',\n",
    " 'NSW 2037',\n",
    " 'NSW 2000',\n",
    " '1568',\n",
    " 'NSW 2120',\n",
    " 'NSW 2120',\n",
    " 'NSW 2120',\n",
    " 'NSW 2010',\n",
    " 'NSW 2000',\n",
    " 'NSW 2077',\n",
    " 'NSW 2000',\n",
    " 'NSW 2000',\n",
    " 'NSW 2022',\n",
    " 'NSW 2010',\n",
    " '1640',\n",
    " 'NSW 2021',\n",
    " 'NSW 2000',\n",
    " 'NSW 2011']  \n",
    "Obviously, 'NSW' can be omitted since Sydney is just in NSW. In addition, '210', '1568' and '1640' should be error postcodes. After manually checking, I find '1568' and '1640' are  valid postcodes (I have no idea why), but '210' should be '2010'. Thus, I fix this manually.  \n",
    "After that, I write a piece of codes to delete 'NSW' before postcodes. The codes are shown in the following paragraph.\n",
    "\n",
    "4. I check all the address names and find some street names are incomplete or abbreviate. I find the following problematic street names:  \n",
    "[Addison road\n",
    "Shaw\n",
    "Shaw\n",
    "Shaw\n",
    "Berith\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Berith\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Berith\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Berith\n",
    "Berith\n",
    "Edward\n",
    "Berith\n",
    "Berith\n",
    "Edward\n",
    "Berith\n",
    "Edward\n",
    "Berith\n",
    "Edward\n",
    "Berith\n",
    "Edward\n",
    "Berith\n",
    "Berith\n",
    "Wolli\n",
    "Berith\n",
    "Wolli\n",
    "Berith\n",
    "Wolli\n",
    "Berith\n",
    "Wolli\n",
    "Berith\n",
    "Wolli\n",
    "Berith\n",
    "Berith\n",
    "Wolli\n",
    "Berith\n",
    "Wolli\n",
    "Berith\n",
    "Wolli\n",
    "Berith\n",
    "Wolli\n",
    "Berith\n",
    "Wolli\n",
    "Berith\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Berith\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Berith\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Wolli\n",
    "Chalmers street\n",
    "York St\n",
    "Liverpool St\n",
    "Argyle St\n",
    "george street\n",
    "George street\n",
    "George st\n",
    "Roberts Ave\n",
    "Henderson St\n",
    "Margaret St\n",
    "Plowman street\n",
    "Pittwater Rd\n",
    "5 Active Pl].  \n",
    "Here, 'Wolli', 'Berith', 'Edward' and 'Shaw' are all provided by the same user '2046smh', who omitted all 'Street' after these names. Thus, I write a piece of codes to add 'Street' after names.  \n",
    "In addition, I fix all the abbreviate names using the codes shown in the following paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef fix_postcodes(postcode):\\n    nsw_re = re.compile( r'NSW' )\\n    if nsw_re.search( str(postcode) ): \\n        return postcode.split(' ')[1]\\n    else:\\n        return postcode\\n\\nif tag_dict['type'] == 'addr' and tag_dict['key'] == 'postcode':\\n    tag_dict['value'] = fix_postcodes( tag_dict['value'] )\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix suburb names\n",
    "'''\n",
    "def fix_suburb_names(name_string):\n",
    "    name_list = name_string.split(' ')\n",
    "    name_tmp = []\n",
    "    for name in name_list:\n",
    "        name_tmp.append( name[0].upper() + name[1:].lower() )\n",
    "    return ' '.join(name_tmp)\n",
    "\n",
    "if tag_dict['type'] == 'addr' and tag_dict['key'] == 'city':\n",
    "    tag_dict['value'] = fix_suburb_names( tag_dict['value'] )\n",
    "'''\n",
    "\n",
    "# fix postcodes\n",
    "'''\n",
    "def fix_postcodes(postcode):\n",
    "    nsw_re = re.compile( r'NSW' )\n",
    "    if nsw_re.search( str(postcode) ): \n",
    "        return postcode.split(' ')[1]\n",
    "    else:\n",
    "        return postcode\n",
    "\n",
    "if tag_dict['type'] == 'addr' and tag_dict['key'] == 'postcode':\n",
    "    tag_dict['value'] = fix_postcodes( tag_dict['value'] )\n",
    "    \n",
    "'''\n",
    "\n",
    "# fix street names\n",
    "'''\n",
    "name_mapping = { \"St\": \"Street\", \"St.\": \"Street\", \"st\": \"Street\", \"street\": \"Street\", \"Ave\": \"Avenue\", \"Av\": \"Avenue\", \"Rd.\": \"Road\", \"Rd\": \"Road\", \"road\": \"Road\", \"Pl\": \"Place\"}\n",
    "\n",
    "def fix_street_name(name_string):\n",
    "    street_type = name_string.split(' ')[-1]\n",
    "    if street_type in name_mapping.keys():\n",
    "        return name_string[:-len(street_type)] + name_mapping[street_type]\n",
    "    else:\n",
    "        return name_str\n",
    "        \n",
    "if tag_dict['type'] == 'addr' and tag_dict['key'] == 'street':\n",
    "    tag_dict['value'] = fix_street_name( tag_dict['value'] )\n",
    "if tag_dict['type'] == 'addr' and tag_dict['key'] == 'street' and tag_dict['value'] in ['Shaw', 'Wolli', 'Edward', 'Berith']:\n",
    "    tag_dict['value'] = tag_dict['value'] + ' Street'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration:\n",
    "    \n",
    "Number of nodes:  \n",
    "SELECT COUNT(*) FROM nodes;  \n",
    "1352655\n",
    "\n",
    "Number of ways:  \n",
    "SELECT COUNT(*) FROM ways;   \n",
    "185519\n",
    "\n",
    "Number of unique users:       \n",
    "SELECT COUNT(DISTINCT(a.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) AS a;   \n",
    "1810\n",
    "\n",
    "Top 10 contributing users:  \n",
    "SELECT a.user, COUNT(a.user) AS num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) AS a GROUP BY a.user ORDER BY num DESC LIMIT 10;\n",
    "\n",
    "\"behemoth14\"   \"117535\"  \n",
    "\"inas\"\t       \"92373\"  \n",
    "\"TheSwavu\"\t   \"69629\"  \n",
    "\"ChopStiR\"\t   \"58134\"  \n",
    "\"aharvey\"\t   \"47864\"  \n",
    "\"Leon K\"\t   \"47615\"  \n",
    "\"cleary\"\t   \"45911\"  \n",
    "\"Rhubarb\"\t   \"40812\"  \n",
    "\"Warin61\"\t   \"40583\"  \n",
    "\"AntBurnett\"   \"38062\"  \n",
    "\n",
    "Top 10 types of shops in Sydney:  \n",
    "CREATE VIEW nodes_ways_tags AS SELECT * FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags);  \n",
    "SELECT value, COUNT() as num FROM nodes_ways_tags WHERE key = 'shop' GROUP BY value ORDER BY num DESC LIMIT 10;  \n",
    "\n",
    "\"supermarket\"\t    \"447\"  \n",
    "\"convenience\"\t    \"301\"  \n",
    "\"mall\"\t            \"167\"  \n",
    "\"alcohol\"\t        \"126\"  \n",
    "\"bakery\"\t        \"99\"  \n",
    "\"car_repair\"\t    \"99\"  \n",
    "\"hairdresser\"\t    \"97\"  \n",
    "\"clothes\"\t        \"93\"  \n",
    "\"bicycle\"\t        \"76\"  \n",
    "\"department_store\"\t\"76\"  \n",
    "\n",
    "Top 10 types of amenities in Sydney:  \n",
    "SELECT value, COUNT() as num FROM nodes_ways_tags WHERE key = 'amenity' GROUP BY value ORDER BY num DESC LIMIT 10;  \n",
    "\n",
    "\"parking\"\t\"3826\"  \n",
    "\"bench\"\t\"1257\"  \n",
    "\"school\"\t\"1014\"  \n",
    "\"restaurant\"\t\"856\"  \n",
    "\"cafe\"\t\"774\"  \n",
    "\"toilets\"\t\"717\"  \n",
    "\"place_of_worship\"\t\"588\"  \n",
    "\"drinking_water\"\t\"583\"  \n",
    "\"fast_food\"\t\"577\"  \n",
    "\"bicycle_parking\"\t\"482\"  \n",
    "\n",
    "Top 10 nodes including the most tags and their users:  \n",
    "SELECT nodes_tags.id, nodes.user, COUNT(nodes_tags.id)  as num FROM nodes JOIN nodes_tags ON nodes.id = nodes_tags.id GROUP BY nodes_tags.id ORDER BY num DESC LIMIT 10;  \n",
    "\n",
    "\"1191079691\"\t\"malcolmh\"\t\"33\"  \n",
    "\"13766899\"\t\"Jojo4u\"\t\"31\"  \n",
    "\"288139026\"\t\"Bryce C Nesbitt\"\t\"26\"  \n",
    "\"250291346\"\t\"Bryce C Nesbitt\"\t\"25\"  \n",
    "\"1618699976\"\t\"mrpulley\"\t\"25\"  \n",
    "\"20930157\"\t\"ntppr\"\t\"19\"  \n",
    "\"4127353279\"\t\"Rhubarb\"\t\"19\"  \n",
    "\"2524742470\"\t\"morray\"\t\"18\"  \n",
    "\"3023984134\"\t\"Alex Brak\"\t\"18\"  \n",
    "\"4115333570\"\t\"Rhubarb\"\t\"18\"  \n",
    "\n",
    "Top 10 ways including the most tags and their users:  \n",
    "SELECT ways_tags.id, ways.user, COUNT(ways_tags.id)  as num FROM ways JOIN ways_tags ON ways.id = ways_tags.id GROUP BY ways_tags.id ORDER BY num DESC LIMIT 10;  \n",
    "\n",
    "\"4960757\"\t\"KatsuOhata\"\t\"33\"  \n",
    "\"5011620\"\t\"Leon K\"\t\"23\"  \n",
    "\"248793312\"\t\"samuelrussell\"\t\"23\"  \n",
    "\"409047656\"\t\"AlexOnTheBus\"\t\"23\"  \n",
    "\"304056519\"\t\"aharvey\"\t\"22\"  \n",
    "\"341469879\"\t\"samuelrussell\"\t\"22\"  \n",
    "\"407606350\"\t\"Biff\"\t\"22\"  \n",
    "\"409047647\"\t\"AlexOnTheBus\"\t\"22\"  \n",
    "\"5011712\"\t\"Leon K\"\t\"21\"  \n",
    "\"10208997\"\t\"Biff\"\t\"21\"  \n",
    "\n",
    "The number of fire station in Sydney:  \n",
    "SELECT COUNT(value) AS 'Num of Fire Station' FROM nodes_ways_tags WHERE value = 'fire_station';  \n",
    "103\n",
    "\n",
    "Types of religions and numbers of places of worship:  \n",
    "SELECT nodes_tags.value as 'Place of Worship', COUNT(*) as num\n",
    "FROM nodes_tags \n",
    "    JOIN (SELECT id FROM nodes_tags WHERE value='place_of_worship')  as a\n",
    "    ON nodes_tags.id=a.id\n",
    "WHERE nodes_tags.key='religion'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC;\n",
    "\n",
    "\"christian\"\t\"323\"  \n",
    "\"muslim\"\t\"8\"  \n",
    "\"buddhist\"\t\"4\"  \n",
    "\"caodaism\"\t\"1\"  \n",
    "\"hindu\"\t\"1\"  \n",
    "\"sikh\"\t\"1\"  \n",
    "\n",
    "Top 10 of denominations:  \n",
    "SELECT a.value, COUNT(a.value) AS num FROM nodes_tags AS a WHERE a.key = 'denomination' GROUP BY a.value ORDER BY num DESC LIMIT 10;  \n",
    "\n",
    "\"anglican\"\t\"57\"\n",
    "\"catholic\"\t\"57\"\n",
    "\"uniting\"\t\"44\"\n",
    "\"baptist\"\t\"22\"\n",
    "\"presbyterian\"\t\"21\"\n",
    "\"roman_catholic\"\t\"11\"\n",
    "\"seventh_day_adventist\"\t\"6\"\n",
    "\"congregational\"\t\"3\"\n",
    "\"greek_orthodox\"\t\"3\"\n",
    "\"mormon\"\t\"3\"\n",
    "\n",
    "Top 10 ways including the most nodes:  \n",
    "SELECT id, COUNT(id) FROM ways_nodes GROUP BY id ORDER BY COUNT(id) DESC LIMIT 10;  \n",
    "\n",
    "\"149668786\"\t\"1789\"  \n",
    "\"150905541\"\t\"1180\"  \n",
    "\"310457827\"\t\"1125\"  \n",
    "\"149949600\"\t\"1110\"  \n",
    "\"149553706\"\t\"943\"  \n",
    "\"398644134\"\t\"935\"  \n",
    "\"414632940\"\t\"923\"  \n",
    "\"224602856\"\t\"901\"  \n",
    "\"366387557\"\t\"841\"  \n",
    "\"225080521\"\t\"837\"\n",
    "\n",
    "Top 10 operators in Sydney:  \n",
    "SELECT a.value, COUNT(a.value) AS num FROM nodes_ways_tags AS a WHERE a.key = 'operator' GROUP BY a.value ORDER BY num DESC LIMIT 10;  \n",
    "\n",
    "\"RailCorp\"\t\"2096\"  \n",
    "\"Sydney Trains\"\t\"238\"  \n",
    "\"Australia Post\"\t\"137\"  \n",
    "\"The University of Sydney\"\t\"118\"  \n",
    "\"Telstra\"\t\"90\"  \n",
    "\"Sydney Water\"\t\"74\"  \n",
    "\"The University of Western Sydney\"\t\"51\"  \n",
    "\"Energy Australia\"\t\"43\"  \n",
    "\"Sydney Catchment Authority\"\t\"37\"  \n",
    "\"City of Sydney\"\t\"32\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Improvement Suggestion:\n",
    "\n",
    "When I clean these data, a poblem in the dataset bothers me much, which is a key may have multiple types of values and express different meanings. For example, when checking the types of buildings, I find the following results: \n",
    "\n",
    "SELECT a.value, COUNT(a.value) AS num FROM nodes_ways_tags AS a WHERE a.key = 'building' GROUP BY a.value ORDER BY num DESC LIMIT 10;  \n",
    "\n",
    "\"yes\"\t\"16377\"  \n",
    "\"house\"\t\"9567\"  \n",
    "\"garage\"\t\"3690\"  \n",
    "\"apartments\"\t\"1387\"  \n",
    "\"residential\"\t\"706\"  \n",
    "\"industrial\"\t\"565\"  \n",
    "\"school\"\t\"552\"  \n",
    "\"commercial\"\t\"546\"  \n",
    "\"university\"\t\"486\"  \n",
    "\"retail\"\t\"387\"  \n",
    "\n",
    "Obviously 'yes' is not a building type, here which may represent that there exists a building. Thus, key \"building\" includes two types of values, and thus data type consistency cannot be maintained, which may confuse users of such a dataset. And this problem cannot be casued by manual input errors due to the large number of this situations. The problem is probably caused by the problematic data format standard.\n",
    "\n",
    "Hence, I suggest to improve the data format standard to make sure one key can only have one type of values, so that a user can identify the exact information he/she wants without such noises.\n",
    "\n",
    "For the key 'building', I can easily write codes to set all {'building': 'yes'} to {'is_building': 'yes'}. However, it is quite hard to solve all similar data problems since such a problem can only be identified through manually checking. Hence, an improved data format standard should be expected and all contributors of OSM are encouraged to strictly follow the standard. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
